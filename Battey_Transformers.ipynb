{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368bd41c",
   "metadata": {},
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70ed150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ------------------------------\n",
    "# Custom Truncated Normal Initialization\n",
    "# ------------------------------\n",
    "def truncated_normal_(tensor, mean=0.0, std=0.2, a=-2.0, b=2.0):\n",
    "    \"\"\"\n",
    "    Custom truncated normal initialization.\n",
    "    This method ensures values stay within the range [a, b].\n",
    "    \"\"\"\n",
    "    lower, upper = (a - mean) / std, (b - mean) / std\n",
    "    tensor.data = torch.distributions.Normal(mean, std).rsample(tensor.shape)\n",
    "    tensor.data = torch.clip(tensor.data, min=a, max=b)\n",
    "    return tensor\n",
    "\n",
    "# ------------------------------\n",
    "# Input Embedding Module (CNN-Based)\n",
    "# ------------------------------\n",
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim=256, kernel_sizes=[4, 3], strides=[2, 2]):\n",
    "        super(InputEmbedding, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(input_dim, embed_dim, kernel_sizes[0], stride=strides[0])\n",
    "        self.bn1 = nn.BatchNorm1d(embed_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(embed_dim, embed_dim, kernel_sizes[1], stride=strides[1])\n",
    "        self.bn2 = nn.BatchNorm1d(embed_dim)\n",
    "\n",
    "        self.cls_token = nn.Parameter(truncated_normal_(torch.empty(1, 1, embed_dim)))\n",
    "        self.pos_embedding = nn.Parameter(truncated_normal_(torch.empty(1, embed_dim + 1, embed_dim)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (batch_size, channels, time_steps)\n",
    "        Output: (batch_size, seq_len+1, embed_dim)\n",
    "        \"\"\"\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # Reshape for transformer (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embedding[:, :x.shape[1], :]\n",
    "\n",
    "        return x\n",
    "\n",
    "# ------------------------------\n",
    "# Multi-Head Self-Attention\n",
    "# ------------------------------\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by number of heads\"\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.qkv_proj = nn.Linear(embed_dim, 3 * embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "\n",
    "        qkv = self.qkv_proj(x)\n",
    "        q, k, v = torch.chunk(qkv, 3, dim=-1)\n",
    "\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
    "        attn_weights = self.attn_dropout(attn_weights)\n",
    "\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, embed_dim)\n",
    "\n",
    "        return self.out_proj(attn_output)\n",
    "\n",
    "# ------------------------------\n",
    "# Feed-Forward Network (MLP Block)\n",
    "# ------------------------------\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, embed_dim, ffn_dim, ffn_dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(embed_dim, ffn_dim)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.fc2 = nn.Linear(ffn_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(ffn_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.fc2(self.gelu(self.fc1(x))))\n",
    "\n",
    "# ------------------------------\n",
    "# DropPath (Stochastic Depth)\n",
    "# ------------------------------\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0. or not self.training:\n",
    "            return x\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        random_tensor = keep_prob + torch.rand(x.shape, device=x.device)\n",
    "        random_tensor.floor_()\n",
    "        return x.div(keep_prob) * random_tensor\n",
    "\n",
    "# ------------------------------\n",
    "# Transformer Block\n",
    "# ------------------------------\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads=16, ffn_dim=1024, drop_path_rate=0.1, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = MultiHeadSelfAttention(embed_dim, num_heads, attn_dropout)\n",
    "        self.drop_path1 = DropPath(drop_path_rate)\n",
    "\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.ffn = FeedForwardNetwork(embed_dim, ffn_dim)\n",
    "        self.drop_path2 = DropPath(drop_path_rate)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.drop_path1(self.attn(self.norm1(x), mask))\n",
    "        x = x + self.drop_path2(self.ffn(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "# ------------------------------\n",
    "# Transformer Encoder\n",
    "# ------------------------------\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=256, num_blocks=4, num_heads=16, ffn_dim=1024, drop_path_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(embed_dim, num_heads, ffn_dim, drop_path_rate)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "\n",
    "# ------------------------------\n",
    "# SOH-TEC Model\n",
    "# ------------------------------\n",
    "class SOHTEC(nn.Module):\n",
    "    def __init__(self, input_dim=5, embed_dim=256, num_blocks=4, num_heads=16, ffn_dim=1024, drop_path_rate=0.1):\n",
    "        super(SOHTEC, self).__init__()\n",
    "\n",
    "        self.embedding = InputEmbedding(input_dim, embed_dim)\n",
    "        self.encoder = TransformerEncoder(embed_dim, num_blocks, num_heads, ffn_dim, drop_path_rate)\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, embed_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim // 2, 1)  # Regression output for SOH estimation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.encoder(x)\n",
    "        return self.mlp_head(x[:, 0])  # Using CLS token for SOH prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c683c",
   "metadata": {},
   "source": [
    "# Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f736469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_csv(\"data/battery/scaledData1_with_soh.csv\")\n",
    "\n",
    "features = ['pack_voltage (V)', 'charge_current (A)', 'max_temperature (℃)', 'min_temperature (℃)', 'soc']\n",
    "X = df[features].values\n",
    "\n",
    "y = df[\"soh (%)\"].values if \"soh (%)\" in df.columns else None\n",
    "\n",
    "scaler_data = StandardScaler()\n",
    "X = scaler_data.fit_transform(X)\n",
    "y = y / 100\n",
    "\n",
    "SEQ_LEN = 100\n",
    "NUM_FEATURES = len(features)\n",
    "\n",
    "def create_sequences(X, y, seq_len):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, len(X) - seq_len, seq_len):\n",
    "        sequences.append(X[i:i+seq_len])\n",
    "        if y is not None:\n",
    "            targets.append(y[i+seq_len-1])\n",
    "    \n",
    "    return np.array(sequences, dtype=np.float32), np.array(targets, dtype=np.float32)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X, y, SEQ_LEN)\n",
    "\n",
    "train_size = int(0.8 * len(X_seq))\n",
    "val_size = int(0.1 * len(X_seq))\n",
    "test_size = len(X_seq) - train_size - val_size\n",
    "\n",
    "X_train, y_train = X_seq[:train_size], y_seq[:train_size]\n",
    "X_val, y_val = X_seq[train_size:train_size+val_size], y_seq[train_size:train_size+val_size]\n",
    "X_test, y_test = X_seq[train_size+val_size:], y_seq[train_size+val_size:]\n",
    "\n",
    "class SOHDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X).permute(0, 2, 1)\n",
    "        self.y = torch.tensor(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = SOHDataset(X_train, y_train)\n",
    "val_dataset = SOHDataset(X_val, y_val)\n",
    "test_dataset = SOHDataset(X_test, y_test)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)  # No shuffle to preserve sequence order\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b677fc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Train Loss: 0.0177, Val Loss: 0.0022\n",
      "Epoch 2/20: Train Loss: 0.0025, Val Loss: 0.0027\n",
      "Epoch 3/20: Train Loss: 0.0018, Val Loss: 0.0012\n",
      "Epoch 4/20: Train Loss: 0.0014, Val Loss: 0.0008\n",
      "Epoch 5/20: Train Loss: 0.0011, Val Loss: 0.0009\n",
      "Epoch 6/20: Train Loss: 0.0010, Val Loss: 0.0009\n",
      "Epoch 7/20: Train Loss: 0.0008, Val Loss: 0.0009\n",
      "Epoch 8/20: Train Loss: 0.0008, Val Loss: 0.0014\n",
      "Epoch 9/20: Train Loss: 0.0008, Val Loss: 0.0011\n",
      "Epoch 10/20: Train Loss: 0.0007, Val Loss: 0.0007\n",
      "Epoch 11/20: Train Loss: 0.0007, Val Loss: 0.0008\n",
      "Epoch 12/20: Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 13/20: Train Loss: 0.0006, Val Loss: 0.0009\n",
      "Epoch 14/20: Train Loss: 0.0006, Val Loss: 0.0008\n",
      "Epoch 15/20: Train Loss: 0.0006, Val Loss: 0.0009\n",
      "Epoch 16/20: Train Loss: 0.0005, Val Loss: 0.0008\n",
      "Epoch 17/20: Train Loss: 0.0005, Val Loss: 0.0009\n",
      "Epoch 18/20: Train Loss: 0.0005, Val Loss: 0.0007\n",
      "Epoch 19/20: Train Loss: 0.0005, Val Loss: 0.0008\n",
      "Epoch 20/20: Train Loss: 0.0005, Val Loss: 0.0007\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SOHTEC(input_dim=NUM_FEATURES, embed_dim=256).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X).squeeze()\n",
    "\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X).squeeze()\n",
    "                val_loss += criterion(outputs, batch_y).item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"best_soh_tec_model.pth\")\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe30149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.0202\n",
      "Test MAE: 0.0176\n",
      "Test R²: -16.6885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.load_state_dict(torch.load(\"best_soh_tec_model.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_X).squeeze()\n",
    "\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "            all_targets.append(batch_y.cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_targets, all_preds))\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a7f62",
   "metadata": {},
   "source": [
    "# Fuel Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a985ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 100 hour splits:\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (401) must match the size of tensor b (400) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 150\u001b[0m\n\u001b[1;32m    147\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_soh_tec_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# TESTS ================================================================================================    \u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_model\u001b[39m(model, test_loader):\n",
      "Cell \u001b[0;32mIn[5], line 119\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m    116\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    117\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 119\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai4sec_bitnet/battery_transformer/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/ai4sec_bitnet/battery_transformer/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/ai4sec_bitnet/battery_transformer/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 90\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     87\u001b[0m X_batch, y_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Pad variable-length sequences to match the longest sequence in the batch\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m X_padded \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch, features, max_time_steps)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m y_padded \u001b[38;5;241m=\u001b[39m pad_sequence(y_batch, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Pad target with -1 (ignored in loss)\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_padded, y_padded\n",
      "File \u001b[0;32m~/Desktop/ai4sec_bitnet/battery_transformer/.venv/lib/python3.12/site-packages/torch/nn/utils/rnn.py:481\u001b[0m, in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value, padding_side)\u001b[0m\n\u001b[1;32m    477\u001b[0m         sequences \u001b[38;5;241m=\u001b[39m sequences\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# assuming trailing dimensions and type of all the Tensors\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# in sequences are same and fetching those from sequences[0]\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    483\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (401) must match the size of tensor b (400) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# DATA =====================================================================================================\n",
    "\n",
    "for hours in [100, 10, 0.25]:\n",
    "\n",
    "    print(f'For {hours} hour splits:\\n')\n",
    "\n",
    "    train_df = pd.read_csv(\"data/fuel_cell/FC1_train_val_filtered.csv\")\n",
    "\n",
    "    features = ['I (A)']\n",
    "    X = train_df[features].values\n",
    "\n",
    "    y = train_df['Utot (V)'].values if 'Utot (V)' in train_df.columns else None\n",
    "    max_y = max(y)\n",
    "\n",
    "    time = train_df['Time (h)'].values\n",
    "\n",
    "    scaler_data = StandardScaler()\n",
    "    X = scaler_data.fit_transform(X)\n",
    "    y = y / max_y\n",
    "\n",
    "    SEQ_LEN = 100\n",
    "    NUM_FEATURES = len(features)\n",
    "\n",
    "    def create_variable_length_sequences(X, y, time, time_window=10.0):\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        current_sequence = []\n",
    "        current_target = []\n",
    "        start_time = time[0]\n",
    "\n",
    "        for i in range(len(time)):\n",
    "            # If the time difference exceeds 10 hours, store the sequence and reset\n",
    "            if time[i] - start_time > time_window:\n",
    "                if len(current_sequence) > 1:  # Avoid single data points\n",
    "                    sequences.append(np.array(current_sequence, dtype=np.float32))\n",
    "                    targets.append(np.array(current_target, dtype=np.float32))\n",
    "                current_sequence = []\n",
    "                current_target = []\n",
    "                start_time = time[i]  # Reset start time\n",
    "\n",
    "            current_sequence.append(X[i])\n",
    "            if y is not None:\n",
    "                current_target.append(y[i])\n",
    "\n",
    "        # Append last sequence if it's non-empty\n",
    "        if len(current_sequence) > 1:\n",
    "            sequences.append(np.array(current_sequence, dtype=np.float32))\n",
    "            targets.append(np.array(current_target, dtype=np.float32))\n",
    "\n",
    "        return sequences, targets\n",
    "\n",
    "    X_var_len, y_var_len = create_variable_length_sequences(X, y, time, hours)\n",
    "\n",
    "    train_size = int(0.8 * len(X_seq))\n",
    "    val_size = int(0.1 * len(X_seq))\n",
    "    test_size = len(X_seq) - train_size - val_size\n",
    "\n",
    "    X_train, y_train = X_var_len[:train_size], y_var_len[:train_size]\n",
    "    X_val, y_val = X_var_len[train_size:train_size+val_size], y_var_len[train_size:train_size+val_size]\n",
    "    X_test, y_test = X_var_len[train_size+val_size:], y_var_len[train_size+val_size:]\n",
    "\n",
    "    class VariableLengthSOHDataset(Dataset):\n",
    "        def __init__(self, X_list, y_list):\n",
    "            self.X_list = [torch.tensor(x).permute(1, 0) for x in X_list]  # Convert to (features, time_steps)\n",
    "            self.y_list = [torch.tensor(y).float() for y in y_list]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.X_list)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            return self.X_list[idx], self.y_list[idx]\n",
    "\n",
    "    # Custom Collate Function for Padding\n",
    "    def collate_fn(batch):\n",
    "        X_batch, y_batch = zip(*batch)\n",
    "\n",
    "        # Pad variable-length sequences to match the longest sequence in the batch\n",
    "        X_padded = pad_sequence(X_batch, batch_first=True, padding_value=0.0)  # (batch, features, max_time_steps)\n",
    "        y_padded = pad_sequence(y_batch, batch_first=True, padding_value=-1)  # Pad target with -1 (ignored in loss)\n",
    "\n",
    "        return X_padded, y_padded\n",
    "\n",
    "    train_dataset = VariableLengthSOHDataset(X_train, y_train)\n",
    "    val_dataset = VariableLengthSOHDataset(X_val, y_val)\n",
    "    test_dataset = VariableLengthSOHDataset(X_test, y_test)\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)  # No shuffle to preserve sequence order\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    # MODEL ================================================================================================\n",
    "\n",
    "    model = SOHTEC(input_dim=NUM_FEATURES, embed_dim=256).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-4)\n",
    "\n",
    "    def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
    "        best_val_loss = float(\"inf\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            for batch_X, batch_y in train_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_X).squeeze()\n",
    "\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in val_loader:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                    outputs = model(batch_X).squeeze()\n",
    "                    val_loss += criterion(outputs, batch_y).item()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(model.state_dict(), \"best_soh_tec_model.pth\")\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)\n",
    "\n",
    "    # TESTS ================================================================================================    \n",
    "\n",
    "    def evaluate_model(model, test_loader):\n",
    "        model.load_state_dict(torch.load(\"best_soh_tec_model.pth\"))\n",
    "        model.eval()\n",
    "\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in test_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X).squeeze()\n",
    "\n",
    "                all_preds.append(outputs.cpu().numpy())\n",
    "                all_targets.append(batch_y.cpu().numpy())\n",
    "\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_targets = np.concatenate(all_targets)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(all_targets, all_preds))\n",
    "        mae = mean_absolute_error(all_targets, all_preds)\n",
    "        r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "        print(f\"Test RMSE: {rmse:.4f}\")\n",
    "        print(f\"Test MAE: {mae:.4f}\")\n",
    "        print(f\"Test R²: {r2:.4f}\")\n",
    "\n",
    "    # Evaluate model\n",
    "    evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb59f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
